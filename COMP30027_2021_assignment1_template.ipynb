{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### ### The University of Melbourne, School of Computing and Information Systems\n",
    "# COMP30027 Machine Learning, 2021 Semester 1\n",
    "\n",
    "## Assignment 1: Pose classification with naive Bayes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Student ID(s):**     1039169, 1044793\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This iPython notebook is a template which you will use for your Assignment 1 submission.\n",
    "\n",
    "Marking will be applied on the four functions that are defined in this notebook, and to your responses to the questions at the end of this notebook (Submitted in a separate PDF file).\n",
    "\n",
    "**NOTE: YOU SHOULD ADD YOUR RESULTS, DIAGRAMS AND IMAGES FROM YOUR OBSERVATIONS IN THIS FILE TO YOUR REPORT (the PDF file).**\n",
    "\n",
    "You may change the prototypes of these functions, and you may write other functions, according to your requirements. We would appreciate it if the required functions were prominent/easy to find.\n",
    "\n",
    "**Adding proper comments to your code is MANDATORY. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load library\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function is used to read data from the csv file\n",
    "def read_data():\n",
    "    # Create URL\n",
    "    test_csv = \"~/pose-classification-with-naive-bayes/COMP30027_2021_assignment1_data/test.csv\"\n",
    "    train_csv = \"~/pose-classification-with-naive-bayes/COMP30027_2021_assignment1_data/train.csv\"\n",
    "    # Load Dataset \n",
    "    test_df = pd.read_csv(test_csv, header = None)\n",
    "    train_df = pd.read_csv(train_csv, header = None)\n",
    "\n",
    "    # Duplicate Dataset\n",
    "    new_test_df = test_df.copy()\n",
    "    new_train_df = train_df.copy()\n",
    "    return new_test_df, new_train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_missing_value(df):\n",
    "    \"\"\"Replace Missing Value in the complete training/testing dataset\"\"\"\n",
    "    for column in df.columns[1:]:\n",
    "        # Replace missing value (9999) with median for each column\n",
    "        df[column] = np.where(df[column] == 9999, np.nan, df[column])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function should prepare the data by reading it from a file and converting it into a useful format for training and testing\n",
    "\n",
    "def preprocess():\n",
    "    \"\"\" Returns DataFrame consist of the testing, training, feature for training/testing and target for training/testing \"\"\"\n",
    "    new_test_df, new_train_df = read_data()\n",
    "    # Replace Missing Value for both testing/training set\n",
    "    new_test_df = replace_missing_value(new_test_df)\n",
    "    new_train_df = replace_missing_value(new_train_df) \n",
    "    # Split the dataset for both training/testing into feature and target \n",
    "    feature_train = new_train_df.iloc[:,1:]\n",
    "    y_train = new_train_df[0]\n",
    "    \n",
    "    feature_test = new_test_df.iloc[:,1:]\n",
    "    y_test = new_test_df[0]\n",
    "    \n",
    "    return new_test_df, new_train_df, feature_train, y_train, feature_test, y_test\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_prior_prob(y_train):\n",
    "    \"\"\" Returns a DataFrame of the prior probability of each pose in log form \"\"\"\n",
    "    \n",
    "    target_count = 0\n",
    "    target_dict = {}\n",
    "    target_dict['Pose'] = []\n",
    "    target_dict['Prior'] = []\n",
    "    for target in np.unique(y_train):\n",
    "        target_dict['Pose'].append(target)\n",
    "        target_count = sum(y_train == target)\n",
    "        target_dict['Prior'].append(target_count / len(y_train))\n",
    "\n",
    "    prior_df = pd.DataFrame(target_dict)\n",
    "    prior_df.set_index(['Pose'], inplace = True)\n",
    "    prior_df['Prior'] = np.log(prior_df['Prior'])\n",
    "    return prior_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_mean_std(new_train_df):\n",
    "    \"\"\" Returns a DataFrame consisting mean and standard deviation for all poses \"\"\"\n",
    "    \n",
    "    # Group by Mean for each Pose\n",
    "    mean_df = new_train_df.groupby([0]).mean()\n",
    "    mean_df.index.names = ['Pose']\n",
    "    mean_df\n",
    "    \n",
    "    # Group by Standard Deviation for each pose\n",
    "    std_df = new_train_df.groupby([0]).std()\n",
    "    std_df.index.names = ['Pose']\n",
    "    std_df\n",
    "    \n",
    "    # x is mean and y is standard deviation\n",
    "    mean_std_df = pd.merge(mean_df, std_df, on = 'Pose', how = 'left')\n",
    "    \n",
    "    return mean_std_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gaussian function\n",
    "import math\n",
    "def gaussian_pdf(x, mean, std):\n",
    "    \"\"\"Return the Gaussian Distribution for a given x data point\"\"\"\n",
    "    return (1/(std * math.sqrt(2*math.pi))*math.exp(-(1/2) * ((x - mean) / std)**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our training/prediction set, we cannot include the class label when calculating likelihood rather we have to infer the posterior probability of all class labels and take the largest posterior probability -> MAP hypothesis. Link : https://en.wikipedia.org/wiki/Naive_Bayes_classifier#Gaussian_na√Øve_Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_likelihood(feature_train, mean_std_df):\n",
    "    \"\"\" Returns a DataFrame of log-likelihood of all 10 poses for every point \"\"\"\n",
    "    \n",
    "    # Likelihood_dict stores the likelihood of all 10 poses for every POINT\n",
    "    likelihood_dict = {}\n",
    "    x = 0\n",
    "    while x < (len(feature_train)): #Go through each instances \n",
    "        y = 0\n",
    "        likelihood_dict['Sample_' + str(x+1)] = []\n",
    "        while y < (len(feature_train.columns)): #Go through each features\n",
    "            pose = 0\n",
    "            while pose < len(mean_std_df): #Go through each unique poses\n",
    "                if np.isnan((feature_train.iloc[x, y])):\n",
    "                    likelihood = np.finfo(float).eps # epsilon for probabilistic smoothing\n",
    "\n",
    "                else:\n",
    "                    # Get the likelihood of each data point using Gaussian Distribution\n",
    "                    likelihood = gaussian_pdf(feature_train.iloc[x, y], mean_std_df.iloc[pose, y], mean_std_df.iloc[pose, y+22])\n",
    "\n",
    "                if (likelihood == 0): # Zero Probability \n",
    "                    likelihood = np.finfo(float).eps # epsilon for probabilistic smoothing\n",
    "                \n",
    "                #Get the Log-likelihood\n",
    "                likelihood = math.log(likelihood)\n",
    "                likelihood_dict['Sample_' + str(x+1)].append(likelihood)\n",
    "                pose += 1\n",
    "            y += 1\n",
    "        x += 1\n",
    "    return pd.DataFrame(likelihood_dict)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_pose_likelihood(feature_train, mean_std_df, likelihood_df):\n",
    "    \"\"\" Returns a DataFrame of log-likelihood of all poses for every sample \"\"\"\n",
    "    \n",
    "    # pose_likelihood stores the likelihood of all 10 poses for every SAMPLE\n",
    "    pose_likelihood = pd.DataFrame(mean_std_df.index)\n",
    "    \n",
    "    y = 0\n",
    "    num_pose = len(mean_std_df)\n",
    "    while y < len(likelihood_df.columns): #Go through each feature\n",
    "        i = 0\n",
    "        lst = []\n",
    "        while i < num_pose: #Go through through each likelihood in an instance for each unique pose\n",
    "            sum_likelihood_pose = 0\n",
    "            x = i\n",
    "            while x < len(likelihood_df):\n",
    "                # Sum the log-likelihood in an instance for each unique pose\n",
    "                sum_likelihood_pose += likelihood_df.iloc[x, y]\n",
    "                x += 10\n",
    "                \n",
    "            lst.append(sum_likelihood_pose)\n",
    "            i += 1\n",
    "        \n",
    "        # Insert into a datafram of sum of the log-likelihood for each unique pose for a given instance\n",
    "        pose_likelihood['Sample_' + str(y+1)] = lst\n",
    "        y += 1\n",
    "    \n",
    "    pose_likelihood.set_index(['Pose'], inplace = True)\n",
    "    return pose_likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_posterior(pose_likelihood, prior_df):\n",
    "    \"\"\" Returns the posterior for all poses of every sample \"\"\"\n",
    "    \n",
    "    posterior_df = pose_likelihood.copy()\n",
    "    # Get the Posterior Probability \n",
    "    for pose in posterior_df.index:\n",
    "        prior = prior_df.loc[pose]\n",
    "        posterior_df.loc[pose] +=  float(prior)\n",
    "        \n",
    "    posterior = posterior_df.T\n",
    "\n",
    "    posterior = posterior.reset_index()\n",
    "    posterior.index.name = ''\n",
    "    posterior.columns.name = ''\n",
    "\n",
    "    posterior.rename(columns={'index':'Sample'}, inplace=True)\n",
    "    # Make 'Sample' column as index\n",
    "    posterior.set_index(['Sample'], inplace = True)\n",
    "    \n",
    "    return posterior, posterior_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function should calculate prior probabilities and likelihoods from the training data and using\n",
    "# them to build a naive Bayes model\n",
    "\n",
    "def train(y_train, new_train_df, feature_train):\n",
    "    # Get the Prior Probability for each pose\n",
    "    prior_df = find_prior_prob(y_train)\n",
    "    # Get the Mean and Standard deviation for each feature for each pose\n",
    "    mean_std_df = find_mean_std(new_train_df)\n",
    "    # Get the log-likelihood of all poses for every sample\n",
    "    likelihood_df = find_likelihood(feature_train, mean_std_df)\n",
    "    # Get the posterior probability of all poses for every sample\n",
    "    pose_likelihood = find_pose_likelihood(feature_train, mean_std_df, likelihood_df)\n",
    "    \n",
    "    return pose_likelihood, prior_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function should predict classes for new items in a test dataset (for the purposes of this assignment, you\n",
    "# can re-use the training data as a test set)\n",
    "\n",
    "def predict(y_train, pose_likelihood, prior_df):\n",
    "    \n",
    "    posterior, posterior_df = find_posterior(pose_likelihood, prior_df)   # Now we have the posteriors\n",
    "    # This is the maximum value for each row, we have to find the label for each of these values\n",
    "    max_post = posterior.max(axis = 1)\n",
    "    max_post = pd.DataFrame(max_post)\n",
    "    max_post.rename(columns={0:'Max_Posterior'}, inplace=True)\n",
    "    \n",
    "    predict_dict = {}\n",
    "    predict_dict['Sample'] = list(max_post.index)\n",
    "    predicted_pose_list = []\n",
    "    \n",
    "    #Convert the posterior probability into the pose name\n",
    "    for r in posterior.index:\n",
    "        index = 0\n",
    "        for c in list(posterior.loc[r]):\n",
    "            if c == max_post.loc[r]['Max_Posterior']:\n",
    "                predicted_pose_list.append(list(posterior_df.index)[index])\n",
    "            index += 1\n",
    "    # Insert the predicted pose name into the dataframe\n",
    "    predict_dict['Predicted_Pose'] = predicted_pose_list\n",
    "\n",
    "    predict_df = pd.DataFrame(predict_dict)\n",
    "    # Insert the true pose name into the dataframe for comparison purpose\n",
    "    predict_df['True_Pose'] = y_train\n",
    "    pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)\n",
    "    return predict_df # Predicted Pose based for each instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function should evaliate the prediction performance by comparing your model‚Äôs class outputs to ground\n",
    "# truth labels\n",
    "\n",
    "def evaluate(predict_df):\n",
    "    num_test_instance = len(predict_df)\n",
    "    predict_df['Correct_Label'] = predict_df['Predicted_Pose'] == predict_df['True_Pose']\n",
    "    # Get the total number of correct label\n",
    "    num_correct_label = len(predict_df[predict_df['Correct_Label'] == True])\n",
    "    # Get the accuracy score\n",
    "    accuracy_score = num_correct_label / num_test_instance\n",
    "    \n",
    "    return accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7402945113788487\n"
     ]
    }
   ],
   "source": [
    "# Preprocess \n",
    "new_test_df, new_train_df, feature_train, y_train, feature_test, y_test = preprocess()\n",
    "\n",
    "# Train\n",
    "pose_likelihood, prior_df = train(y_train, new_train_df, feature_train)\n",
    "\n",
    "# Predict\n",
    "predict_df = predict(y_train, pose_likelihood, prior_df)\n",
    "\n",
    "# Evaluate\n",
    "print(evaluate(predict_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions \n",
    "\n",
    "\n",
    "If you are in a group of 1, you will respond to **two** questions of your choosing.\n",
    "\n",
    "If you are in a group of 2, you will respond to **four** questions of your choosing.\n",
    "\n",
    "A response to a question should take about 100‚Äì250 words, and make reference to the data wherever possible.\n",
    "\n",
    "#### NOTE: you may develope codes or functions to help respond to the question here, but your formal answer should be submitted separately as a PDF."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1\n",
    "Since this is a multiclass classification problem, there are multiple ways to compute precision, recall, and F-score for this classifier. Implement at least two of the methods from the \"Model Evaluation\" lecture and discuss any differences between them. (The implementation should be your own and should not just call a pre-existing function.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision = TP / (TP + FP).  \n",
    "Recall = TP / (TP + FN). \n",
    "F1 = 2*Precision*Recall / (Precision + Recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp_df = predict_df[predict_df['True_Pose'] == 'bridge'] # Actual Bridge\n",
    "tp_fn_list = list(tp_df['Predicted_Pose'] == tp_df['True_Pose']) # Predicted Bridge and Actual Bridge is True\n",
    "tp = 0\n",
    "fn = 0\n",
    "for i in tp_fn_list:\n",
    "    if i == True:\n",
    "        tp += 1\n",
    "    else:\n",
    "        fn += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17_64\n"
     ]
    }
   ],
   "source": [
    "print(str(tp) + '_' + str(fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "fp_df = predict_df[predict_df['True_Pose'] != 'bridge'] # Actual Not Bridge\n",
    "fp_list = list(fp_df['Predicted_Pose'] == 'bridge') # Predicted Bridge and Actual Not Bridge\n",
    "fp = 0\n",
    "for i in fp_list:\n",
    "    if i == True:\n",
    "        fp += 1\n",
    "print(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "654"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tn = len(predict_df) - tp - fn - fp\n",
    "tn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_dict = {}\n",
    "for pose in list(predict_df['True_Pose'].unique()):\n",
    "    confusion_list = []\n",
    "    #confusion_dict[pose] = confusion_list\n",
    "    tp_df = predict_df[predict_df['True_Pose'] == pose] # Actual Bridge\n",
    "    tp_fn_list = list(tp_df['Predicted_Pose'] == tp_df['True_Pose']) # Predicted Bridge and Actual Bridge is True\n",
    "    tp = 0\n",
    "    fn = 0\n",
    "    for x in tp_fn_list:\n",
    "        if x == True:\n",
    "            tp += 1\n",
    "        else:\n",
    "            fn += 1\n",
    "    fp_df = predict_df[predict_df['True_Pose'] != pose] # Actual Not Bridge\n",
    "    fp_list = list(fp_df['Predicted_Pose'] == pose) # Predicted Bridge and Actual Not Bridge\n",
    "    fp = 0\n",
    "    for i in fp_list:\n",
    "        if i == True:\n",
    "            fp += 1\n",
    "    tn = len(predict_df) - tp - fn - fp\n",
    "    \n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn) \n",
    "    f1 = (2*precision*recall) / (precision + recall)\n",
    "    #print('Precision : ' + str(precision))\n",
    "    #print('recall : ' + str(recall))\n",
    "    #print('f1 : ' + str(f1))\n",
    "    \n",
    "    confusion_list.append(tp)\n",
    "    confusion_list.append(fn)\n",
    "    confusion_list.append(fp)\n",
    "    confusion_list.append(tn)\n",
    "    confusion_list.append(precision)\n",
    "    confusion_list.append(recall)\n",
    "    confusion_list.append(f1)\n",
    "    \n",
    "    confusion_dict[pose] = confusion_list\n",
    "    #print('True Positive : ' + str(tp))\n",
    "    #print('False Negative : ' + str(fn))\n",
    "    #print('False Positive : ' + str(fp))\n",
    "    #print('True Negative : ' + str(tn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7392575055101048\n",
      "0.7156254548083576\n"
     ]
    }
   ],
   "source": [
    "# 1. Macro-averaging\n",
    "sum_precision = 0\n",
    "sum_recall = 0\n",
    "for precision_pose in confusion_dict.keys():\n",
    "    sum_precision += confusion_dict[precision_pose][4]\n",
    "    sum_recall += confusion_dict[precision_pose][5]\n",
    "    \n",
    "macro_average_precision = sum_precision / len(confusion_dict.keys())\n",
    "macro_average_recall = sum_recall / len(confusion_dict.keys())\n",
    "#f1 = (2*macro_average_precision*macro_average_recall) / (macro_average_precision+ macro_average_recall)\n",
    "print(macro_average_precision)\n",
    "print(macro_average_recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7402945113788487\n",
      "0.7402945113788487\n"
     ]
    }
   ],
   "source": [
    "# 2. Micro-averaging\n",
    "tp_sum = 0\n",
    "fp_sum = 0\n",
    "fn_sum = 0\n",
    "\n",
    "for precision_pose in confusion_dict.keys():\n",
    "    tp_sum += confusion_dict[precision_pose][0]\n",
    "    fn_sum += confusion_dict[precision_pose][1]\n",
    "    fp_sum += confusion_dict[precision_pose][2]\n",
    "\n",
    "micro_average_precision = tp_sum / (tp_sum + fp_sum)\n",
    "micro_average_recall = tp_sum / (tp_sum + fn_sum)\n",
    "print(micro_average_precision)\n",
    "print(micro_average_recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2\n",
    "The Gaussian naƒ±ve Bayes classifier assumes that numeric attributes come from a Gaussian distribution. Is this assumption always true for the numeric attributes in this dataset? Identify some cases where the Gaussian assumption is violated and describe any evidence (or lack thereof) that this has some effect on the classifier‚Äôs predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No\n",
    "\n",
    "Evidence: Many of the pose (bridge are mistaken as downwarddog) and (seatedforwardbend mistaken as child)\n",
    "\n",
    "Gaussian Distribution assumes : mean = 0 and standard deviation = sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature 1: KstestResult(statistic=0.39424631630152945, pvalue=4.939960373172725e-83)\n",
      "feature 2: KstestResult(statistic=0.38131250232818703, pvalue=1.151369046625854e-89)\n",
      "feature 3: KstestResult(statistic=0.746019154009615, pvalue=2.1849940734e-313)\n",
      "feature 4: KstestResult(statistic=0.6968736264662918, pvalue=9.661078928049572e-252)\n",
      "feature 5: KstestResult(statistic=0.7200063665734007, pvalue=3.592892236987334e-289)\n",
      "feature 6: KstestResult(statistic=0.6843096973515523, pvalue=5.614484308392732e-243)\n",
      "feature 7: KstestResult(statistic=0.3704906967405037, pvalue=6.254988392017793e-81)\n",
      "feature 8: KstestResult(statistic=0.7944992898607758, pvalue=0.0)\n",
      "feature 9: KstestResult(statistic=0.74932673397712, pvalue=4.029804521855616e-304)\n",
      "feature 10: KstestResult(statistic=0.8003199316315173, pvalue=0.0)\n",
      "feature 11: KstestResult(statistic=0.7418340856173791, pvalue=1.491985106513682e-296)\n",
      "feature 12: KstestResult(statistic=0.8563727592482392, pvalue=0.0)\n",
      "feature 13: KstestResult(statistic=0.9061583573638167, pvalue=0.0)\n",
      "feature 14: KstestResult(statistic=0.6880959023911888, pvalue=1.7668074028189894e-257)\n",
      "feature 15: KstestResult(statistic=0.68196108897531, pvalue=3.593251114877271e-239)\n",
      "feature 16: KstestResult(statistic=0.6904667582120589, pvalue=1.7384137295262677e-261)\n",
      "feature 17: KstestResult(statistic=0.6696137168436151, pvalue=6.371496497711022e-231)\n",
      "feature 18: KstestResult(statistic=0.6340525676248328, pvalue=3.841852492309084e-255)\n",
      "feature 19: KstestResult(statistic=0.797519792581922, pvalue=0.0)\n",
      "feature 20: KstestResult(statistic=0.9903051881483538, pvalue=0.0)\n",
      "feature 21: KstestResult(statistic=0.7747798914992994, pvalue=0.0)\n",
      "feature 22: KstestResult(statistic=0.9835730661490294, pvalue=0.0)\n"
     ]
    }
   ],
   "source": [
    "# Normal Distribution is known as a Gaussian Distribution\n",
    "from scipy import stats\n",
    "\n",
    "for i in feature_train.columns:\n",
    "    x = feature_train[i].dropna()\n",
    "    print('feature ' + str(i) + ': ' + str(stats.kstest(x, 'norm')))\n",
    "#All are not normal "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3\n",
    "Implement a kernel density estimate (KDE) naive Bayes classifier and compare its performance to the Gaussian naive Bayes classifier. Recall that KDE has kernel bandwidth as a free parameter -- you can choose an arbitrary value for this, but a value in the range 5-25 is recommended. Discuss any differences you observe between the Gaussian and KDE naive Bayes classifiers. (As with the Gaussian naive Bayes, this KDE naive Bayes implementation should be your own and should not just call a pre-existing function.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KernelDensity\n",
    "X = feature_train.dropna()\n",
    "kde = KernelDensity(kernel='gaussian', bandwidth=0.2).fit(X)\n",
    "#kde.score_samples(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4\n",
    "Instead of using an arbitrary kernel bandwidth for the KDE naive Bayes classifier, use random hold-out or cross-validation to choose the kernel bandwidth. Discuss how this changes the model performance compared to using an arbitrary kernel bandwidth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q5\n",
    "Naive Bayes ignores missing values, but in pose recognition tasks the missing values can be informative. Missing values indicate that some part of the body was obscured and sometimes this is relevant to the pose (e.g., holding one hand behind the back). Are missing values useful for this task? Implement a method that incorporates information about missing values and demonstrate whether it changes the classification results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q6\n",
    "Engineer your own pose features from the provided keypoints. Instead of using the (x,y) positions of keypoints, you might consider the angles of the limbs or body, or the distances between pairs of keypoints. How does a naive Bayes classifier based on your engineered features compare to the classifier using (x,y) values? Please note that we are interested in explainable features for pose recognition, so simply putting the (x,y) values in a neural network or similar to get an arbitrary embedding will not receive full credit for this question. You should be able to explain the rationale behind your proposed features. Also, don't forget the conditional independence assumption of naive Bayes when proposing new features -- a large set of highly-correlated features may not work well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
